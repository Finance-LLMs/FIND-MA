{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e611d317",
   "metadata": {},
   "source": [
    "# Building a Retrieval-Augmented Generation (RAG) System\n",
    "\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) system using:\n",
    "- LangChain for document processing and vector operations\n",
    "- FAISS for efficient similarity search\n",
    "- Ollama for local LLM inference\n",
    "- HuggingFace embeddings for text vectorization\n",
    "\n",
    "We'll build a system that can answer questions about PDF documents by:\n",
    "1. Loading and processing PDFs\n",
    "2. Creating vector embeddings from the text\n",
    "3. Performing similarity search for relevant content\n",
    "4. Generating contextual answers using a local LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a03a6",
   "metadata": {},
   "source": [
    "## 1. Setup Environment and Import Libraries\n",
    "\n",
    "First, we need to install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec55a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install required packages\n",
    "# %pip install langchain faiss-cpu pypdf2 ollama sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e7f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb561664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12dac79",
   "metadata": {},
   "source": [
    "Now, let's import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439bf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import ollama\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from IPython.display import Markdown, display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628bfd5",
   "metadata": {},
   "source": [
    "## 2. PDF Loading and Text Extraction\n",
    "\n",
    "We'll create a function to load PDF files and extract text from them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b18e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Load a PDF file and extract text from it.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        str: Extracted text from the PDF\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    with open(file_path, \"rb\") as file:\n",
    "        reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        num_pages = len(reader.pages)\n",
    "        \n",
    "        print(f\"Processing {num_pages} pages...\")\n",
    "        \n",
    "        for i, page in enumerate(reader.pages):\n",
    "            page_text = page.extract_text()\n",
    "            text += page_text + \"\\n\"\n",
    "            # Print progress\n",
    "            if (i+1) % 5 == 0 or i+1 == num_pages:\n",
    "                print(f\"Processed {i+1}/{num_pages} pages\")\n",
    "                \n",
    "    print(f\"Extracted {len(text)} characters of text.\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23fb5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add after the load_pdf function\n",
    "\n",
    "def load_pdfs_from_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Load all PDF files from a directory.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing PDFs\n",
    "        \n",
    "    Returns:\n",
    "        list: List of tuples (filename, text_content)\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    \n",
    "    if not os.path.exists(directory_path):\n",
    "        raise FileNotFoundError(f\"The directory {directory_path} does not exist.\")\n",
    "    \n",
    "    pdf_files = glob.glob(os.path.join(directory_path, \"*.pdf\"))\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in {directory_path}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files in {directory_path}\")\n",
    "    \n",
    "    all_documents = []\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            print(f\"\\nProcessing: {os.path.basename(pdf_file)}\")\n",
    "            pdf_text = load_pdf(pdf_file)\n",
    "            all_documents.append((os.path.basename(pdf_file), pdf_text))\n",
    "            print(f\"Successfully loaded {os.path.basename(pdf_file)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {pdf_file}: {str(e)}\")\n",
    "    \n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc15788",
   "metadata": {},
   "source": [
    "Let's test our PDF loading function with a sample PDF. For this example, we'll use the annual report PDF mentioned in the original code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c205d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 PDF files in ../Reports\n",
      "\n",
      "Processing: infosys-ar-20.pdf\n",
      "Processing 313 pages...\n",
      "Processed 5/313 pages\n",
      "Processed 10/313 pages\n",
      "Processed 15/313 pages\n",
      "Processed 20/313 pages\n",
      "Processed 25/313 pages\n",
      "Processed 30/313 pages\n",
      "Processed 35/313 pages\n",
      "Processed 40/313 pages\n",
      "Processed 45/313 pages\n",
      "Processed 50/313 pages\n",
      "Processed 55/313 pages\n",
      "Processed 60/313 pages\n",
      "Processed 65/313 pages\n",
      "Processed 70/313 pages\n",
      "Processed 75/313 pages\n",
      "Processed 80/313 pages\n",
      "Processed 85/313 pages\n",
      "Processed 90/313 pages\n",
      "Processed 95/313 pages\n",
      "Processed 100/313 pages\n",
      "Processed 105/313 pages\n",
      "Processed 110/313 pages\n",
      "Processed 115/313 pages\n",
      "Processed 120/313 pages\n",
      "Processed 125/313 pages\n",
      "Processed 130/313 pages\n",
      "Processed 135/313 pages\n",
      "Processed 140/313 pages\n",
      "Processed 145/313 pages\n",
      "Processed 150/313 pages\n",
      "Processed 155/313 pages\n",
      "Processed 160/313 pages\n",
      "Processed 165/313 pages\n",
      "Processed 170/313 pages\n",
      "Processed 175/313 pages\n",
      "Processed 180/313 pages\n",
      "Processed 185/313 pages\n",
      "Processed 190/313 pages\n",
      "Processed 195/313 pages\n",
      "Processed 200/313 pages\n",
      "Processed 205/313 pages\n",
      "Processed 210/313 pages\n",
      "Processed 215/313 pages\n",
      "Processed 220/313 pages\n",
      "Processed 225/313 pages\n",
      "Processed 230/313 pages\n",
      "Processed 235/313 pages\n",
      "Processed 240/313 pages\n",
      "Processed 245/313 pages\n",
      "Processed 250/313 pages\n",
      "Processed 255/313 pages\n",
      "Processed 260/313 pages\n",
      "Processed 265/313 pages\n",
      "Processed 270/313 pages\n",
      "Processed 275/313 pages\n",
      "Processed 280/313 pages\n",
      "Processed 285/313 pages\n",
      "Processed 290/313 pages\n",
      "Processed 295/313 pages\n",
      "Processed 300/313 pages\n",
      "Processed 305/313 pages\n",
      "Processed 310/313 pages\n",
      "Processed 313/313 pages\n",
      "Extracted 1157455 characters of text.\n",
      "Successfully loaded infosys-ar-20.pdf\n",
      "\n",
      "Processing: infosys-ar-21.pdf\n",
      "Processing 320 pages...\n",
      "Processed 5/320 pages\n",
      "Processed 10/320 pages\n",
      "Processed 15/320 pages\n",
      "Processed 20/320 pages\n",
      "Processed 25/320 pages\n",
      "Processed 30/320 pages\n",
      "Processed 35/320 pages\n",
      "Processed 40/320 pages\n",
      "Processed 45/320 pages\n",
      "Processed 50/320 pages\n",
      "Processed 55/320 pages\n",
      "Processed 60/320 pages\n",
      "Processed 65/320 pages\n",
      "Processed 70/320 pages\n",
      "Processed 75/320 pages\n",
      "Processed 80/320 pages\n",
      "Processed 85/320 pages\n",
      "Processed 90/320 pages\n",
      "Processed 95/320 pages\n",
      "Processed 100/320 pages\n",
      "Processed 105/320 pages\n",
      "Processed 110/320 pages\n",
      "Processed 115/320 pages\n",
      "Processed 120/320 pages\n",
      "Processed 125/320 pages\n",
      "Processed 130/320 pages\n",
      "Processed 135/320 pages\n",
      "Processed 140/320 pages\n",
      "Processed 145/320 pages\n",
      "Processed 150/320 pages\n",
      "Processed 155/320 pages\n",
      "Processed 160/320 pages\n",
      "Processed 165/320 pages\n",
      "Processed 170/320 pages\n",
      "Processed 175/320 pages\n",
      "Processed 180/320 pages\n",
      "Processed 185/320 pages\n",
      "Processed 190/320 pages\n",
      "Processed 195/320 pages\n",
      "Processed 200/320 pages\n",
      "Processed 205/320 pages\n",
      "Processed 210/320 pages\n",
      "Processed 215/320 pages\n",
      "Processed 220/320 pages\n",
      "Processed 225/320 pages\n",
      "Processed 230/320 pages\n",
      "Processed 235/320 pages\n",
      "Processed 240/320 pages\n",
      "Processed 245/320 pages\n",
      "Processed 250/320 pages\n",
      "Processed 255/320 pages\n",
      "Processed 260/320 pages\n",
      "Processed 265/320 pages\n",
      "Processed 270/320 pages\n",
      "Processed 275/320 pages\n",
      "Processed 280/320 pages\n",
      "Processed 285/320 pages\n",
      "Processed 290/320 pages\n",
      "Processed 295/320 pages\n",
      "Processed 300/320 pages\n",
      "Processed 305/320 pages\n",
      "Processed 310/320 pages\n",
      "Processed 315/320 pages\n",
      "Processed 320/320 pages\n",
      "Extracted 1175640 characters of text.\n",
      "Successfully loaded infosys-ar-21.pdf\n",
      "\n",
      "Processing: infosys-ar-23.pdf\n",
      "Processing 358 pages...\n",
      "Processed 5/358 pages\n",
      "Processed 10/358 pages\n",
      "Processed 15/358 pages\n",
      "Processed 20/358 pages\n",
      "Processed 25/358 pages\n",
      "Processed 30/358 pages\n",
      "Processed 35/358 pages\n",
      "Processed 40/358 pages\n",
      "Processed 45/358 pages\n",
      "Processed 50/358 pages\n",
      "Processed 55/358 pages\n",
      "Processed 60/358 pages\n",
      "Processed 65/358 pages\n",
      "Processed 70/358 pages\n",
      "Processed 75/358 pages\n",
      "Processed 80/358 pages\n",
      "Processed 85/358 pages\n",
      "Processed 90/358 pages\n",
      "Processed 95/358 pages\n",
      "Processed 100/358 pages\n",
      "Processed 105/358 pages\n",
      "Processed 110/358 pages\n",
      "Processed 115/358 pages\n",
      "Processed 120/358 pages\n",
      "Processed 125/358 pages\n",
      "Processed 130/358 pages\n",
      "Processed 135/358 pages\n",
      "Processed 140/358 pages\n",
      "Processed 145/358 pages\n",
      "Processed 150/358 pages\n",
      "Processed 155/358 pages\n",
      "Processed 160/358 pages\n",
      "Processed 165/358 pages\n",
      "Processed 170/358 pages\n",
      "Processed 175/358 pages\n",
      "Processed 180/358 pages\n",
      "Processed 185/358 pages\n",
      "Processed 190/358 pages\n",
      "Processed 195/358 pages\n",
      "Processed 200/358 pages\n",
      "Processed 205/358 pages\n",
      "Processed 210/358 pages\n",
      "Processed 215/358 pages\n",
      "Processed 220/358 pages\n",
      "Processed 225/358 pages\n",
      "Processed 230/358 pages\n",
      "Processed 235/358 pages\n",
      "Processed 240/358 pages\n",
      "Processed 245/358 pages\n",
      "Processed 250/358 pages\n",
      "Processed 255/358 pages\n",
      "Processed 260/358 pages\n",
      "Processed 265/358 pages\n",
      "Processed 270/358 pages\n",
      "Processed 275/358 pages\n",
      "Processed 280/358 pages\n",
      "Processed 285/358 pages\n",
      "Processed 290/358 pages\n",
      "Processed 295/358 pages\n",
      "Processed 300/358 pages\n",
      "Processed 305/358 pages\n",
      "Processed 310/358 pages\n",
      "Processed 315/358 pages\n",
      "Processed 320/358 pages\n",
      "Processed 325/358 pages\n",
      "Processed 330/358 pages\n",
      "Processed 335/358 pages\n",
      "Processed 340/358 pages\n",
      "Processed 345/358 pages\n",
      "Processed 350/358 pages\n",
      "Processed 355/358 pages\n",
      "Processed 358/358 pages\n",
      "Extracted 1186003 characters of text.\n",
      "Successfully loaded infosys-ar-23.pdf\n",
      "\n",
      "Processing: infosys-ar-24.pdf\n",
      "Processing 352 pages...\n",
      "Processed 5/352 pages\n",
      "Processed 10/352 pages\n",
      "Processed 15/352 pages\n",
      "Processed 20/352 pages\n",
      "Processed 25/352 pages\n",
      "Processed 30/352 pages\n",
      "Processed 35/352 pages\n",
      "Processed 40/352 pages\n",
      "Processed 45/352 pages\n",
      "Processed 50/352 pages\n",
      "Processed 55/352 pages\n",
      "Processed 60/352 pages\n",
      "Processed 65/352 pages\n",
      "Processed 70/352 pages\n",
      "Processed 75/352 pages\n",
      "Processed 80/352 pages\n",
      "Processed 85/352 pages\n",
      "Processed 90/352 pages\n",
      "Processed 95/352 pages\n",
      "Processed 100/352 pages\n",
      "Processed 105/352 pages\n",
      "Processed 110/352 pages\n",
      "Processed 115/352 pages\n",
      "Processed 120/352 pages\n",
      "Processed 125/352 pages\n",
      "Processed 130/352 pages\n",
      "Processed 135/352 pages\n",
      "Processed 140/352 pages\n",
      "Processed 145/352 pages\n",
      "Processed 150/352 pages\n",
      "Processed 155/352 pages\n",
      "Processed 160/352 pages\n",
      "Processed 165/352 pages\n",
      "Processed 170/352 pages\n",
      "Processed 175/352 pages\n",
      "Processed 180/352 pages\n",
      "Processed 185/352 pages\n",
      "Processed 190/352 pages\n",
      "Processed 195/352 pages\n",
      "Processed 200/352 pages\n",
      "Processed 205/352 pages\n",
      "Processed 210/352 pages\n",
      "Processed 215/352 pages\n",
      "Processed 220/352 pages\n",
      "Processed 225/352 pages\n",
      "Processed 230/352 pages\n",
      "Processed 235/352 pages\n",
      "Processed 240/352 pages\n",
      "Processed 245/352 pages\n",
      "Processed 250/352 pages\n",
      "Processed 255/352 pages\n",
      "Processed 260/352 pages\n",
      "Processed 265/352 pages\n",
      "Processed 270/352 pages\n",
      "Processed 275/352 pages\n",
      "Processed 280/352 pages\n",
      "Processed 285/352 pages\n",
      "Processed 290/352 pages\n",
      "Processed 295/352 pages\n",
      "Processed 300/352 pages\n",
      "Processed 305/352 pages\n",
      "Processed 310/352 pages\n",
      "Processed 315/352 pages\n",
      "Processed 320/352 pages\n",
      "Processed 325/352 pages\n",
      "Processed 330/352 pages\n",
      "Processed 335/352 pages\n",
      "Processed 340/352 pages\n",
      "Processed 345/352 pages\n",
      "Processed 350/352 pages\n",
      "Processed 352/352 pages\n",
      "Extracted 1139227 characters of text.\n",
      "Successfully loaded infosys-ar-24.pdf\n",
      "\n",
      "Processing: infosys-ar-22.pdf\n",
      "Processing 363 pages...\n",
      "Processed 5/363 pages\n",
      "Processed 10/363 pages\n",
      "Processed 15/363 pages\n",
      "Processed 20/363 pages\n",
      "Processed 25/363 pages\n",
      "Processed 30/363 pages\n",
      "Processed 35/363 pages\n",
      "Processed 40/363 pages\n",
      "Processed 45/363 pages\n",
      "Processed 50/363 pages\n",
      "Processed 55/363 pages\n",
      "Processed 60/363 pages\n",
      "Processed 65/363 pages\n",
      "Processed 70/363 pages\n",
      "Processed 75/363 pages\n",
      "Processed 80/363 pages\n",
      "Processed 85/363 pages\n",
      "Processed 90/363 pages\n",
      "Processed 95/363 pages\n",
      "Processed 100/363 pages\n",
      "Processed 105/363 pages\n",
      "Processed 110/363 pages\n",
      "Processed 115/363 pages\n",
      "Processed 120/363 pages\n",
      "Processed 125/363 pages\n",
      "Processed 130/363 pages\n",
      "Processed 135/363 pages\n",
      "Processed 140/363 pages\n",
      "Processed 145/363 pages\n",
      "Processed 150/363 pages\n",
      "Processed 155/363 pages\n",
      "Processed 160/363 pages\n",
      "Processed 165/363 pages\n",
      "Processed 170/363 pages\n",
      "Processed 175/363 pages\n",
      "Processed 180/363 pages\n",
      "Processed 185/363 pages\n",
      "Processed 190/363 pages\n",
      "Processed 195/363 pages\n",
      "Processed 200/363 pages\n",
      "Processed 205/363 pages\n",
      "Processed 210/363 pages\n",
      "Processed 215/363 pages\n",
      "Processed 220/363 pages\n",
      "Processed 225/363 pages\n",
      "Processed 230/363 pages\n",
      "Processed 235/363 pages\n",
      "Processed 240/363 pages\n",
      "Processed 245/363 pages\n",
      "Processed 250/363 pages\n",
      "Processed 255/363 pages\n",
      "Processed 260/363 pages\n",
      "Processed 265/363 pages\n",
      "Processed 270/363 pages\n",
      "Processed 275/363 pages\n",
      "Processed 280/363 pages\n",
      "Processed 285/363 pages\n",
      "Processed 290/363 pages\n",
      "Processed 295/363 pages\n",
      "Processed 300/363 pages\n",
      "Processed 305/363 pages\n",
      "Processed 310/363 pages\n",
      "Processed 315/363 pages\n",
      "Processed 320/363 pages\n",
      "Processed 325/363 pages\n",
      "Processed 330/363 pages\n",
      "Processed 335/363 pages\n",
      "Processed 340/363 pages\n",
      "Processed 345/363 pages\n",
      "Processed 350/363 pages\n",
      "Processed 355/363 pages\n",
      "Processed 360/363 pages\n",
      "Processed 363/363 pages\n",
      "Extracted 1285227 characters of text.\n",
      "Successfully loaded infosys-ar-22.pdf\n",
      "\n",
      "Successfully loaded 5 documents\n",
      "Total text length across all documents: 5943552 characters\n",
      "\n",
      "infosys-ar-20.pdf: 1157455 characters\n",
      "Sample text (first 200 characters):\n",
      "--------------------------------------------------\n",
      "Being Resilient.\n",
      "That’s Live Enterprise.\n",
      "Annual Report 2019–20\n",
      "\n",
      "RESPONSIVE VALUE CHAINS CREATIVE TALENTINTUITIVE DECISIONSPERCEPTIVE EXPERIENCEResilience: What differentiates  \n",
      "the Live Enterprise\n",
      "Inf...\n",
      "--------------------------------------------------\n",
      "\n",
      "infosys-ar-21.pdf: 1175640 characters\n",
      "Sample text (first 200 characters):\n",
      "--------------------------------------------------\n",
      "Annual Report 2020-21Cloud chaos \n",
      "to clarity\n",
      "\n",
      "Navigating towards cloud clarity | 1 Are we meeting business needs with agility? Are we \n",
      "efficient in the way we operate? Are we continuously \n",
      "unlocking i...\n",
      "--------------------------------------------------\n",
      "\n",
      "infosys-ar-23.pdf: 1186003 characters\n",
      "Sample text (first 200 characters):\n",
      "--------------------------------------------------\n",
      "Integrated Annual Report 2022-23\n",
      "The context surrounding \n",
      "an enterprise, created, \n",
      "and influenced by multiple \n",
      "inherently uncertain forces, can \n",
      "significantly impact the fortunes \n",
      "of a business. While...\n",
      "--------------------------------------------------\n",
      "... and 2 more document(s)\n"
     ]
    }
   ],
   "source": [
    "# Replace the PDF loading cell with this\n",
    "\n",
    "# Path to the directory containing PDFs\n",
    "reports_directory = \"../Reports\"\n",
    "\n",
    "try:\n",
    "    # Load all PDFs from the directory\n",
    "    documents = load_pdfs_from_directory(reports_directory)\n",
    "    \n",
    "    if documents:\n",
    "        print(f\"\\nSuccessfully loaded {len(documents)} documents\")\n",
    "        \n",
    "        # Display summary of loaded documents\n",
    "        total_text_length = sum(len(text) for _, text in documents)\n",
    "        print(f\"Total text length across all documents: {total_text_length} characters\")\n",
    "        \n",
    "        for filename, text in documents[:3]:  # Show details for first 3 documents\n",
    "            print(f\"\\n{filename}: {len(text)} characters\")\n",
    "            print(\"Sample text (first 200 characters):\")\n",
    "            print(\"-\" * 50)\n",
    "            print(text[:200] + \"...\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "        if len(documents) > 3:\n",
    "            print(f\"... and {len(documents) - 3} more document(s)\")\n",
    "    else:\n",
    "        print(\"No documents were loaded. Using sample text for demonstration.\")\n",
    "        # Create a placeholder for demonstration purposes\n",
    "        documents = [(\"sample.pdf\", \"This is a sample text that simulates content from a PDF file. \" * 100)]\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    # Create a placeholder for demonstration purposes\n",
    "    documents = [(\"sample.pdf\", \"This is a sample text that simulates content from a PDF file. \" * 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40a6c3",
   "metadata": {},
   "source": [
    "## 3. Text Chunking and Vector Store Creation\n",
    "\n",
    "For effective retrieval, we need to split the text into manageable chunks and create embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252435e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the create_vector_store function with this version\n",
    "\n",
    "def create_vector_store(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split text into chunks and create a vector store with metadata.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of (filename, text) tuples\n",
    "        chunk_size (int): Size of each chunk\n",
    "        chunk_overlap (int): Overlap between chunks\n",
    "        \n",
    "    Returns:\n",
    "        FAISS: Vector store object\n",
    "    \"\"\"\n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    all_chunks = []\n",
    "    all_metadatas = []\n",
    "    \n",
    "    for filename, text in documents:\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        metadatas = [{\"source\": filename} for _ in range(len(chunks))]\n",
    "        \n",
    "        all_chunks.extend(chunks)\n",
    "        all_metadatas.extend(metadatas)\n",
    "    \n",
    "    chunking_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Split text into {len(all_chunks)} chunks across {len(documents)} documents (took {chunking_time:.2f} seconds)\")\n",
    "    \n",
    "    # Create embeddings\n",
    "    print(\"Initializing embedding model...\")\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    \n",
    "    # Create vector store\n",
    "    print(\"Creating vector store...\")\n",
    "    start_time = time.time()\n",
    "    vector_store = FAISS.from_texts(all_chunks, embeddings, metadatas=all_metadatas)\n",
    "    vectorization_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Vector store created with {len(all_chunks)} vectors (took {vectorization_time:.2f} seconds)\")\n",
    "    \n",
    "    return vector_store, all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00744cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split text into 7545 chunks across 5 documents (took 0.12 seconds)\n",
      "Initializing embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2349815/475983215.py:39: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store...\n",
      "Vector store created with 7545 vectors (took 7.12 seconds)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average chunk length: 939.4 characters\n",
      "Shortest chunk: 15 characters\n",
      "Longest chunk: 999 characters\n"
     ]
    }
   ],
   "source": [
    "# Replace the vector store creation cell with this\n",
    "\n",
    "# Create vector store from all documents\n",
    "vector_store, chunks = create_vector_store(documents)\n",
    "\n",
    "# Display some statistics about the chunks\n",
    "chunk_lengths = [len(chunk) for chunk in chunks]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(chunk_lengths, bins=20)\n",
    "plt.title('Distribution of Chunk Lengths')\n",
    "plt.xlabel('Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average chunk length: {np.mean(chunk_lengths):.1f} characters\")\n",
    "print(f\"Shortest chunk: {min(chunk_lengths)} characters\")\n",
    "print(f\"Longest chunk: {max(chunk_lengths)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835ae46",
   "metadata": {},
   "source": [
    "Let's examine a few chunks to understand what our text looks like after chunking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2428a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"chunk_preview.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for chunk in chunks[:3]:\n",
    "#         f.write(chunk[:100] + \"...\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb962514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display a few example chunks\n",
    "# for i in range(min(3, len(chunks))):\n",
    "#     print(f\"Chunk {i+1} ({len(chunks[i])} characters):\")\n",
    "#     print(\"-\" * 50)\n",
    "#     print(chunks[i][:300] + \"...\")  # Show first 300 chars\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85565931",
   "metadata": {},
   "source": [
    "## 4. Question Answering with Ollama\n",
    "\n",
    "Now, let's implement the question answering functionality using the Ollama API with the deepseek-r1 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7f9a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ollama(query, context):\n",
    "    \"\"\"\n",
    "    Generate an answer using Ollama API based on the provided context.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user's question\n",
    "        context (str): Context information retrieved from the vector store\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated answer from the model\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Answer the question based on the following context:\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"deepseek-r1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b4049c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the answer_question function to show source information\n",
    "\n",
    "def answer_question(query, vector_store, k=4):\n",
    "    \"\"\"\n",
    "    Answer a question using RAG approach.\n",
    "    \n",
    "    Args:\n",
    "        query (str): User's question\n",
    "        vector_store: FAISS vector store\n",
    "        k (int): Number of relevant chunks to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        str: Answer to the question\n",
    "    \"\"\"\n",
    "    print(f\"Searching for context relevant to: '{query}'\")\n",
    "    \n",
    "    # Retrieve relevant chunks\n",
    "    start_time = time.time()\n",
    "    docs = vector_store.similarity_search(query, k=k)\n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Retrieved {len(docs)} relevant chunks (took {search_time:.2f} seconds)\")\n",
    "    \n",
    "    # Format context with source information\n",
    "    context_parts = []\n",
    "    for doc in docs:\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        context_parts.append(f\"Source: {source}\\n{doc.page_content}\")\n",
    "    \n",
    "    context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
    "    context_length = len(context)\n",
    "    \n",
    "    print(f\"Sending prompt with context of {context_length} characters to Ollama...\")\n",
    "    \n",
    "    # Get answer from Ollama\n",
    "    start_time = time.time()\n",
    "    answer = ask_ollama(query, context)\n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Generated answer of {len(answer)} characters (took {generation_time:.2f} seconds)\")\n",
    "    \n",
    "    return answer, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e070d5d",
   "metadata": {},
   "source": [
    "Let's test our question answering function with a sample question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9265555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for context relevant to: 'What are the main financial highlights?'\n",
      "Retrieved 4 relevant chunks (took 0.03 seconds)\n",
      "Sending prompt with context of 4033 characters to Ollama...\n",
      "Generated answer of 4201 characters (took 12.54 seconds)\n",
      "\n",
      "Question: What are the main financial highlights?\n",
      "\n",
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "<think>\n",
      "Okay, so I need to figure out the main financial highlights from the provided context. Let me start by reading through each source carefully and noting down the key points.\n",
      "\n",
      "First, looking at infosys-ar-23.pdf, there's a section titled \"Consolidated Cash and Investments.\" It mentions that cash and investments include various instruments with high credit ratings. There's also a part about investments in startups which help access innovation for client benefits. However, this seems more like an overview rather than specific financial highlights.\n",
      "\n",
      "Next, another part of infosys-ar-23.pdf details the consolidated cash and investments broken down by different segments: Financial Services, Retail Communication, Energy, Utilities, Resources and Services, Manufacturing Hi-Tech, Life Sciences, All other segments, and Total. The figures are in crores (in India's numbering system). It looks like the company has significant revenues across these segments. However, to find financial highlights, I might need more specific metrics.\n",
      "\n",
      "Moving on to infosys-ar-24.pdf, there's a section titled \"Performance Highlights.\" Here, key metrics are provided:\n",
      "\n",
      "- Return on Equity (ROE) is 17%, which is quite high and indicates strong profitability.\n",
      "- Earnings Before Tax (EBT) is ₹5,709.8 crores.\n",
      "- Net Profit is ₹4,236.3 crores.\n",
      "- Dividends paid are ₹1,217.4 crores, with a dividend payout ratio of 28% and a return on equity of 17%. These ratios suggest good financial health as they indicate how well the company is distributing profits to shareholders.\n",
      "\n",
      "Looking at the revenue by geography in infosys-ar-23.pdf, it's split into North America, Europe, India, and Rest of the World. The total revenues for each region are given alongside subtotals. This breakdown shows where most of the company's revenue comes from, which can be a highlight as it indicates regional strength.\n",
      "\n",
      "The table under \"Revenues by Geography\" in infosys-ar-23.pdf lists the regions with their respective revenues. For example, North America contributes 90,724 crore, Europe 37,675 crore, and so on. This clearly shows that a significant portion of the company's revenue comes from these major regions.\n",
      "\n",
      "Additionally, the \"Revenues by Segment\" table (from infosys-ar-23.pdf) provides insights into which segments are performing well. For instance, Life Sciences seems to have lower figures compared to other segments, but this might not be as relevant unless it's a specific focus area.\n",
      "\n",
      "I also notice that in both reports, there's mention of investments in startups and innovation. However, since the question is about financial highlights, these might fall outside the main metrics unless they directly impact financial performance.\n",
      "\n",
      "Putting all this together, the main financial highlights would include high ROE, significant net profits, substantial cash reserves from both operations and investments, consistent revenue growth across key regions like North America and Europe, and effective dividend distribution. The company's ability to generate these figures despite being a large company suggests strong management and strategy.\n",
      "</think>\n",
      "\n",
      "The main financial highlights of Infosys for the years ended March 31, 2023, and March 31, 2022, are as follows:\n",
      "\n",
      "1. **Profitability**: \n",
      "   - Return on Equity (ROE) is 17%, indicating strong profitability.\n",
      "   - Earnings Before Tax (EBT) amounts to ₹5,709.8 crores.\n",
      "   - Net Profit reaches ₹4,236.3 crores.\n",
      "\n",
      "2. **Cash Reserves**:\n",
      "   - The company holds substantial cash and investments from both operational activities and startup ventures, underscoring robust financial stability.\n",
      "\n",
      "3. **Revenue Growth**: \n",
      "   - Significant revenue contributions are observed across key regions: North America (90,724 crore), Europe (37,675 crore), India (3,861 crore), and Rest of the World (14,507 crore). This highlights strong performance in major markets.\n",
      "\n",
      "4. **Dividend Distribution**: \n",
      "   - The company pays ₹1,217.4 crores in dividends, with a dividend payout ratio of 28% and a return on equity of 17%, indicating effective distribution to shareholders.\n",
      "\n",
      "These metrics collectively reflect Infosys's strong financial health, profitability, and strategic performance across its operations.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Top relevant context used:\n",
      "\n",
      "Context chunk 1:\n",
      "...Our consolidated cash and \n",
      "investments include deposits in banks, investments in liquid mutual funds, fixed maturity plan securities, commercial paper, quoted bonds issued by government and semi-government organizations, non-convertible debentures and CDs or certificates of deposits – all such instr...\n",
      "\n",
      "Context chunk 2:\n",
      "...and strategic requirements and \n",
      "unforeseen events while also earning \n",
      "sufficient returns.\n",
      "Our consolidated cash and \n",
      "investments include deposits \n",
      "in banks, investments in liquid \n",
      "mutual funds, fixed maturity plan \n",
      "securities, commercial paper, quoted \n",
      "bonds issued by government and \n",
      "semi-government...\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample question\n",
    "sample_question = \"What are the main financial highlights?\"\n",
    "answer, relevant_docs = answer_question(sample_question, vector_store)\n",
    "\n",
    "print(\"\\nQuestion:\", sample_question)\n",
    "print(\"\\nAnswer:\")\n",
    "print(\"-\" * 80)\n",
    "print(answer)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nTop relevant context used:\")\n",
    "for i, doc in enumerate(relevant_docs[:2]):  # Show only first 2 contexts\n",
    "    print(f\"\\nContext chunk {i+1}:\")\n",
    "    print(\"...\" + doc.page_content[:300] + \"...\")  # First 300 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c1d93",
   "metadata": {},
   "source": [
    "## 5. Interactive Demo\n",
    "\n",
    "Let's create an interactive demo using IPython widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53724400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_demo(vector_store):\n",
    "    \"\"\"Create an interactive demo for question answering\"\"\"\n",
    "    \n",
    "    # Create widgets\n",
    "    question_input = widgets.Text(\n",
    "        value='',\n",
    "        description='Question:',\n",
    "        placeholder='Type your question here...',\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    k_slider = widgets.IntSlider(\n",
    "        value=4,\n",
    "        min=1,\n",
    "        max=10,\n",
    "        step=1,\n",
    "        description='Context chunks:',\n",
    "        layout=widgets.Layout(width='50%')\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Submit button\n",
    "    button = widgets.Button(\n",
    "        description='Get Answer',\n",
    "        button_style='primary',\n",
    "        tooltip='Click to get the answer',\n",
    "        icon='search'\n",
    "    )\n",
    "    \n",
    "    def on_button_clicked(_):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            if question_input.value.strip():\n",
    "                print(f\"Question: {question_input.value}\")\n",
    "                print(\"Generating answer...\")\n",
    "                answer, docs = answer_question(question_input.value, vector_store, k=k_slider.value)\n",
    "                display(Markdown(\"### Answer:\"))\n",
    "                display(Markdown(answer))\n",
    "                \n",
    "                display(Markdown(\"### Sources:\"))\n",
    "                for i, doc in enumerate(docs):\n",
    "                    display(Markdown(f\"**Source {i+1}** (extract):\\n> {doc.page_content[:150]}...\"))\n",
    "            else:\n",
    "                print(\"Please enter a question.\")\n",
    "    \n",
    "    button.on_click(on_button_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>RAG Question Answering System</h3>\"),\n",
    "        widgets.HBox([question_input, button]),\n",
    "        k_slider,\n",
    "        output\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1204fbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3beef093fba14ec68f2665557f437650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>RAG Question Answering System</h3>'), HBox(children=(Text(value='', description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display the interactive demo\n",
    "demo = create_interactive_demo(vector_store)\n",
    "display(demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be953a44",
   "metadata": {},
   "source": [
    "## 6. Error Handling and Improvements\n",
    "\n",
    "Let's enhance our system with better error handling and explore potential improvements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d93f875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"A more robust implementation of our RAG system with error handling\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"deepseek-r1\", \n",
    "                 embeddings_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                 chunk_size=1000, chunk_overlap=200):\n",
    "        self.model_name = model_name\n",
    "        self.embeddings_model_name = embeddings_model\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.vector_store = None\n",
    "        self.chunks = []\n",
    "        self.pdf_text = \"\"\n",
    "        \n",
    "    def load_document(self, file_path):\n",
    "        \"\"\"Load document and handle errors\"\"\"\n",
    "        try:\n",
    "            if file_path.lower().endswith('.pdf'):\n",
    "                self.pdf_text = load_pdf(file_path)\n",
    "                return True, f\"Successfully loaded PDF with {len(self.pdf_text)} characters\"\n",
    "            else:\n",
    "                return False, \"Only PDF files are currently supported\"\n",
    "        except FileNotFoundError:\n",
    "            return False, f\"File not found: {file_path}\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Error loading document: {str(e)}\"\n",
    "    \n",
    "    def process_document(self):\n",
    "        \"\"\"Process the loaded document and create vector store\"\"\"\n",
    "        try:\n",
    "            if not self.pdf_text:\n",
    "                return False, \"No document loaded. Please load a document first.\"\n",
    "            \n",
    "            self.vector_store, self.chunks = create_vector_store(\n",
    "                self.pdf_text, self.chunk_size, self.chunk_overlap\n",
    "            )\n",
    "            return True, f\"Successfully processed document into {len(self.chunks)} chunks\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Error processing document: {str(e)}\"\n",
    "    \n",
    "    def answer_query(self, query, k=4):\n",
    "        \"\"\"Answer a query with improved error handling\"\"\"\n",
    "        try:\n",
    "            if not self.vector_store:\n",
    "                return False, \"Vector store not initialized. Process a document first.\"\n",
    "            \n",
    "            if not query.strip():\n",
    "                return False, \"Query cannot be empty\"\n",
    "            \n",
    "            answer, docs = answer_question(query, self.vector_store, k)\n",
    "            return True, {\"answer\": answer, \"sources\": docs}\n",
    "        except Exception as e:\n",
    "            return False, f\"Error answering query: {str(e)}\"\n",
    "    \n",
    "    def suggest_improvements(self):\n",
    "        \"\"\"Suggest possible improvements to the RAG system\"\"\"\n",
    "        improvements = [\n",
    "            \"**Implement document metadata** - Track source information for each chunk\",\n",
    "            \"**Add document pre-processing** - Clean and normalize text before chunking\",\n",
    "            \"**Experiment with different embedding models** - Try models like E5, BGE, or INSTRUCTOR\",\n",
    "            \"**Implement re-ranking** - Use a cross-encoder to re-rank the retrieved chunks\",\n",
    "            \"**Add chat history** - Maintain conversation context for follow-up questions\",\n",
    "            \"**Optimize chunking strategy** - Try semantic chunking instead of character-based\",\n",
    "            \"**Implement hybrid search** - Combine vector search with keyword-based search\",\n",
    "            \"**Add evaluation metrics** - Measure relevance and answer quality\"\n",
    "        ]\n",
    "        return improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c1b068e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential improvements for the RAG system:\n",
      "1. **Implement document metadata** - Track source information for each chunk\n",
      "2. **Add document pre-processing** - Clean and normalize text before chunking\n",
      "3. **Experiment with different embedding models** - Try models like E5, BGE, or INSTRUCTOR\n",
      "4. **Implement re-ranking** - Use a cross-encoder to re-rank the retrieved chunks\n",
      "5. **Add chat history** - Maintain conversation context for follow-up questions\n",
      "6. **Optimize chunking strategy** - Try semantic chunking instead of character-based\n",
      "7. **Implement hybrid search** - Combine vector search with keyword-based search\n",
      "8. **Add evaluation metrics** - Measure relevance and answer quality\n"
     ]
    }
   ],
   "source": [
    "# Create and test our improved RAG system\n",
    "rag = RAGSystem()\n",
    "\n",
    "# Show potential improvements\n",
    "print(\"Potential improvements for the RAG system:\")\n",
    "for i, improvement in enumerate(rag.suggest_improvements(), 1):\n",
    "    print(f\"{i}. {improvement}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a506484a",
   "metadata": {},
   "source": [
    "### Summary and Conclusion\n",
    "\n",
    "In this notebook, we've built a complete Retrieval-Augmented Generation (RAG) system that:\n",
    "\n",
    "1. Loads and processes PDF documents\n",
    "2. Chunks text and creates vector embeddings\n",
    "3. Performs similarity search to find relevant context\n",
    "4. Uses Ollama with the deepseek-r1 model to generate answers\n",
    "5. Provides an interactive interface for querying the document\n",
    "\n",
    "This implementation demonstrates the core components of a RAG system, but there are many ways to improve it further, as outlined in the improvements section.\n",
    "\n",
    "Key takeaways:\n",
    "- RAG enhances LLM responses with relevant context from specific documents\n",
    "- The quality of chunking and embeddings directly impacts retrieval performance\n",
    "- Local models like those in Ollama provide privacy and control advantages\n",
    "- Error handling is crucial for production-ready RAG systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93326bac",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5947443b",
   "metadata": {},
   "source": [
    "## 7. News Agent - Financial News Analysis\n",
    "\n",
    "Now let's implement a News Agent that fetches and analyzes news articles about companies. The News Agent will:\n",
    "1. Fetch recent news articles using the News API\n",
    "2. Extract relevant information from the articles\n",
    "3. Analyze sentiment and key points\n",
    "4. Integrate this information with our existing RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "057dad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for News Agent\n",
    "# %pip install newsapi-python requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3397d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No News API key provided. You'll need to set your API key.\n",
      "Get a free API key from https://newsapi.org/\n",
      "Then set it with: news_agent.set_api_key('your_api_key')\n",
      "News Agent initialized!\n",
      "Note: To use the News Agent, you need to get an API key from https://newsapi.org/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "\n",
    "class NewsAgent:\n",
    "    \"\"\"Agent for fetching and analyzing financial news\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=None):\n",
    "        \"\"\"Initialize the News Agent with API key\"\"\"\n",
    "        self.api_key = api_key or os.environ.get(\"NEWS_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            print(\"Warning: No News API key provided. You'll need to set your API key.\")\n",
    "            print(\"Get a free API key from https://newsapi.org/\")\n",
    "            print(\"Then set it with: news_agent.set_api_key('your_api_key')\")\n",
    "        self.base_url = \"https://newsapi.org/v2\"\n",
    "        \n",
    "    def set_api_key(self, api_key: str) -> None:\n",
    "        \"\"\"Set the News API key\"\"\"\n",
    "        self.api_key = api_key\n",
    "        print(\"API key set successfully!\")\n",
    "        \n",
    "    def get_company_news(self, company_name: str, days: int = 7, \n",
    "                        max_results: int = 10) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Fetch news about a specific company\"\"\"\n",
    "        if not self.api_key:\n",
    "            return [{\n",
    "                \"title\": \"Error: No API key provided\",\n",
    "                \"description\": \"Please set your News API key first\",\n",
    "                \"content\": \"To use the News Agent, you need to set your API key.\"\n",
    "            }]\n",
    "        \n",
    "        # Calculate date range\n",
    "        end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        start_date = (datetime.now() - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        # Prepare request\n",
    "        endpoint = f\"{self.base_url}/everything\"\n",
    "        params = {\n",
    "            \"q\": company_name,\n",
    "            \"from\": start_date,\n",
    "            \"to\": end_date,\n",
    "            \"sortBy\": \"relevancy\",\n",
    "            \"language\": \"en\",\n",
    "            \"pageSize\": max_results,\n",
    "            \"apiKey\": self.api_key\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(endpoint, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get(\"status\") == \"ok\":\n",
    "                articles = data.get(\"articles\", [])\n",
    "                return [{\n",
    "                    \"title\": article.get(\"title\"),\n",
    "                    \"source\": article.get(\"source\", {}).get(\"name\"),\n",
    "                    \"author\": article.get(\"author\"),\n",
    "                    \"published_at\": article.get(\"publishedAt\"),\n",
    "                    \"description\": article.get(\"description\"),\n",
    "                    \"content\": article.get(\"content\"),\n",
    "                    \"url\": article.get(\"url\")\n",
    "                } for article in articles]\n",
    "            else:\n",
    "                print(f\"API Error: {data.get('message')}\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching news: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_industry_news(self, industry: str, days: int = 7, \n",
    "                         max_results: int = 10) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Fetch news about a specific industry\"\"\"\n",
    "        return self.get_company_news(f\"{industry} industry\", days, max_results)\n",
    "    \n",
    "    def analyze_sentiment(self, articles: List[Dict[str, Any]], \n",
    "                         llm_model: str = \"deepseek-r1\") -> Dict[str, Any]:\n",
    "        \"\"\"Analyze sentiment and key points from articles using Ollama\"\"\"\n",
    "        if not articles:\n",
    "            return {\"error\": \"No articles to analyze\"}\n",
    "        \n",
    "        # Prepare articles text for analysis\n",
    "        articles_text = \"\\n\\n\".join([f\"Title: {a['title']}\\n\" + \n",
    "                                    f\"Source: {a['source']}\\n\" +\n",
    "                                    f\"Date: {a['published_at']}\\n\" +\n",
    "                                    f\"Description: {a['description']}\\n\" + \n",
    "                                    f\"Content: {a['content']}\" \n",
    "                                   for a in articles[:5]])\n",
    "        \n",
    "        # Prepare prompt for Ollama\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following news articles and provide:\n",
    "        1. Overall sentiment (positive, neutral, or negative)\n",
    "        2. Key points or trends mentioned\n",
    "        3. Any significant events or announcements\n",
    "        4. Potential financial implications\n",
    "        \n",
    "        Articles:\n",
    "        {articles_text}\n",
    "        \n",
    "        Your analysis should be concise and focus on financial relevance.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=llm_model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            analysis = response['message']['content']\n",
    "            \n",
    "            return {\n",
    "                \"analysis\": analysis,\n",
    "                \"articles_analyzed\": len(articles[:5]),\n",
    "                \"total_articles\": len(articles)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing articles: {e}\")\n",
    "            return {\"error\": f\"Analysis failed: {str(e)}\"}\n",
    "    \n",
    "    def summarize_news(self, company_name: str, days: int = 7) -> Dict[str, Any]:\n",
    "        \"\"\"Complete workflow to get and analyze news for a company\"\"\"\n",
    "        print(f\"Fetching news for {company_name} over the past {days} days...\")\n",
    "        articles = self.get_company_news(company_name, days)\n",
    "        \n",
    "        if not articles or (len(articles) == 1 and \"Error\" in articles[0].get(\"title\", \"\")):\n",
    "            return {\"error\": \"Could not fetch news articles. Check your API key.\"}\n",
    "        \n",
    "        print(f\"Found {len(articles)} articles. Analyzing content...\")\n",
    "        analysis = self.analyze_sentiment(articles)\n",
    "        \n",
    "        # Format result\n",
    "        result = {\n",
    "            \"company\": company_name,\n",
    "            \"period\": f\"{days} days\",\n",
    "            \"articles_count\": len(articles),\n",
    "            \"analysis\": analysis.get(\"analysis\"),\n",
    "            \"articles\": [{\n",
    "                \"title\": a[\"title\"],\n",
    "                \"source\": a[\"source\"],\n",
    "                \"date\": a[\"published_at\"],\n",
    "                \"url\": a[\"url\"]\n",
    "            } for a in articles[:10]]\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Create an instance of the News Agent\n",
    "news_agent = NewsAgent()\n",
    "print(\"News Agent initialized!\")\n",
    "print(\"Note: To use the News Agent, you need to get an API key from https://newsapi.org/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0db53b",
   "metadata": {},
   "source": [
    "### Using the News Agent\n",
    "\n",
    "To use the News Agent, you need to:\n",
    "1. Get a free API key from [News API](https://newsapi.org/)\n",
    "2. Set your API key\n",
    "3. Fetch and analyze news for a company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d74ec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key set successfully!\n",
      "Analyzing sample news articles about Infosys...\n",
      "\n",
      "News Analysis:\n",
      "================================================================================\n",
      "<think>\n",
      "Alright, I'm looking at these three articles about Infosys. Let me try to break down each one step by step.\n",
      "\n",
      "First article: Infosys reports strong Q2 earnings and raises guidance. The revenue jumped 7.3% year-over-year, which is a positive sign. They also increased their FY24 growth estimate from 4-6% to 5-7%. This shows they're confident in their future performance, so that's another positive point.\n",
      "\n",
      "The second article talks about an AI partnership with Microsoft. This sounds strategic and could lead to new opportunities or revenue streams. However, it might also come with costs or integration challenges that could affect the company financially. But since it's a partnership, I think the immediate financial impact is less clear but potentially positive in the long run.\n",
      "\n",
      "Third article mentions Infosys hiring 20,000 fresh graduates next year. Hiring this many young talent suggests they're optimistic about their future growth. However, if there are headwinds like economic slowdowns, does that mean they might not meet expectations? The Chief HR Officer says it's because of confidence in medium to long-term growth, so maybe it's a positive sign despite the current environment.\n",
      "\n",
      "Overall sentiment: Positive because all three articles indicate growth and increased optimism. The earnings beat estimates and new partnerships show profitability potential, while hiring reflects a proactive approach towards future growth.\n",
      "</think>\n",
      "\n",
      "**Analysis of Infosys News Articles**\n",
      "\n",
      "1. **Title: Infosys Reports Strong Q2 Earnings, Raises Guidance**\n",
      "   - **Overall Sentiment:** Positive\n",
      "     - The company exceeded analyst expectations with $4.72 billion revenue and raised its FY24 guidance to 5-7% growth from a lower estimate.\n",
      "   - **Key Points/Trends Mentioned:**\n",
      "     - Q2 Revenue: $4.72 billion, +7.3% YoY\n",
      "     - FY24 Guidance Raised to 5-7%\n",
      "     - Digital Services contributing 62% of total revenue.\n",
      "   - **Significant Events/Announcements:**\n",
      "     - Earnings beat expectations and guidance update.\n",
      "   - **Potential Financial Implications:**\n",
      "     - Strong Q2 results boost investor confidence and may lead to higher stock prices or increased interest from partners.\n",
      "\n",
      "2. **Title: Infosys Announces New AI Partnership with Microsoft**\n",
      "   - **Overall Sentiment:** Positive\n",
      "     - The strategic partnership aims to enhance enterprise solutions, indicating potential new revenue streams.\n",
      "   - **Key Points/Trends Mentioned:**\n",
      "     - Strategic AI partnership between Infosys and Microsoft\n",
      "     - Focus on integrating Azure OpenAI Service with industry-specific platforms.\n",
      "   - **Significant Events/Announcements:**\n",
      "     - New AI-powered solutions development agreement.\n",
      "   - **Potential Financial Implications:**\n",
      "     - Could lead to licensing fees, new product sales, or increased revenue from AI services.\n",
      "\n",
      "3. **Title: Infosys to Hire 20,000 Fresh Graduates in FY24**\n",
      "   - **Overall Sentiment:** Positive\n",
      "     - Despite industry challenges, the company's hiring strategy reflects long-term growth confidence.\n",
      "   - **Key Points/Trends Mentioned:**\n",
      "     - Plan to hire 20,000 fresh graduates next year.\n",
      "     - Reflects confidence in medium to long-term growth prospects.\n",
      "   - **Significant Events/Announcements:**\n",
      "     - Hiring initiative despite economic headwinds.\n",
      "   - **Potential Financial Implications:**\n",
      "     - May impact recruiting costs but could enhance future employee productivity and innovation.\n",
      "\n",
      "**Overall Sentiment:** Positive\n",
      "\n",
      "The articles collectively indicate strong financial performance, strategic initiatives, and optimistic growth prospects for Infosys. The positive sentiment is driven by beating earnings estimates, raising guidance, entering a new AI partnership, and strategically planning to hire fresh graduates, all of which are indicators of a thriving company with potential for future success.\n",
      "================================================================================\n",
      "\n",
      "Articles analyzed:\n",
      "1. Infosys Reports Strong Q2 Earnings, Raises Guidance (Financial Times)\n",
      "2. Infosys Announces New AI Partnership with Microsoft (Tech Insider)\n",
      "3. Infosys to Hire 20,000 Fresh Graduates in FY24 (Business Standard)\n"
     ]
    }
   ],
   "source": [
    "# Set your News API key here\n",
    "news_agent.set_api_key(\"80b4dae2eaeb4e17b88b71eb24d6ea25\")\n",
    "\n",
    "# For demo without an API key, let's create some sample data\n",
    "sample_news = [\n",
    "    {\n",
    "        \"title\": \"Infosys Reports Strong Q2 Earnings, Raises Guidance\",\n",
    "        \"source\": \"Financial Times\",\n",
    "        \"author\": \"John Smith\",\n",
    "        \"published_at\": \"2023-10-15T09:30:00Z\",\n",
    "        \"description\": \"Infosys reported better-than-expected Q2 earnings and raised its annual guidance.\",\n",
    "        \"content\": \"Infosys reported Q2 revenue of $4.72 billion, up 7.3% year-over-year, beating analyst estimates. The company raised its FY24 revenue growth guidance to 5-7% from 4-6% previously. Digital services now account for 62% of total revenue.\",\n",
    "        \"url\": \"https://example.com/infosys-earnings\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Infosys Announces New AI Partnership with Microsoft\",\n",
    "        \"source\": \"Tech Insider\",\n",
    "        \"author\": \"Emily Johnson\",\n",
    "        \"published_at\": \"2023-10-12T14:15:00Z\",\n",
    "        \"description\": \"Infosys and Microsoft announce strategic AI partnership to enhance enterprise solutions.\",\n",
    "        \"content\": \"Infosys today announced a strategic partnership with Microsoft to develop and deploy AI-powered enterprise solutions. The partnership will focus on integrating Microsoft's Azure OpenAI Service with Infosys' industry-specific platforms.\",\n",
    "        \"url\": \"https://example.com/infosys-microsoft\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Infosys to Hire 20,000 Fresh Graduates in FY24\",\n",
    "        \"source\": \"Business Standard\",\n",
    "        \"author\": \"Rahul Patel\",\n",
    "        \"published_at\": \"2023-10-10T11:45:00Z\",\n",
    "        \"description\": \"Despite industry headwinds, Infosys plans to onboard 20,000 fresh graduates in the current fiscal year.\",\n",
    "        \"content\": \"Infosys has announced plans to hire 20,000 fresh graduates in FY24, despite the overall slowdown in tech hiring. The company's Chief HR Officer stated this reflects their confidence in medium to long-term growth prospects.\",\n",
    "        \"url\": \"https://example.com/infosys-hiring\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to demonstrate news analysis with sample data\n",
    "def analyze_sample_news():\n",
    "    print(\"Analyzing sample news articles about Infosys...\")\n",
    "    # Using the news_agent's analyze_sentiment method with our sample data\n",
    "    analysis = news_agent.analyze_sentiment(sample_news)\n",
    "    \n",
    "    print(\"\\nNews Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(analysis.get(\"analysis\"))\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display article headlines\n",
    "    print(\"\\nArticles analyzed:\")\n",
    "    for i, article in enumerate(sample_news):\n",
    "        print(f\"{i+1}. {article['title']} ({article['source']})\")\n",
    "\n",
    "# Run the sample analysis\n",
    "analyze_sample_news()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70d5e1",
   "metadata": {},
   "source": [
    "### Creating an Interactive News Analysis Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68d9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_news_analysis_widget():\n",
    "    \"\"\"Create an interactive widget for news analysis\"\"\"\n",
    "    # Create widgets\n",
    "    company_input = widgets.Text(\n",
    "        value='Infosys',\n",
    "        description='Company:',\n",
    "        placeholder='Enter company name',\n",
    "        layout=widgets.Layout(width='60%')\n",
    "    )\n",
    "    \n",
    "    days_slider = widgets.IntSlider(\n",
    "        value=7,\n",
    "        min=1,\n",
    "        max=30,\n",
    "        step=1,\n",
    "        description='Days:',\n",
    "        layout=widgets.Layout(width='50%')\n",
    "    )\n",
    "    \n",
    "    api_key_input = widgets.Text(\n",
    "        value='',\n",
    "        description='API Key:',\n",
    "        placeholder='Enter your News API key',\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Submit button\n",
    "    button = widgets.Button(\n",
    "        description='Analyze News',\n",
    "        button_style='info',\n",
    "        tooltip='Click to analyze news',\n",
    "        icon='newspaper'\n",
    "    )\n",
    "    \n",
    "    # Use sample data button\n",
    "    sample_button = widgets.Button(\n",
    "        description='Use Sample Data',\n",
    "        button_style='warning',\n",
    "        tooltip='Use sample data instead of API'\n",
    "    )\n",
    "    \n",
    "    def on_api_analyze_clicked(_):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            if api_key_input.value.strip():\n",
    "                news_agent.set_api_key(api_key_input.value.strip())\n",
    "            \n",
    "            if company_input.value.strip():\n",
    "                print(f\"Analyzing news for {company_input.value} over the past {days_slider.value} days...\")\n",
    "                try:\n",
    "                    result = news_agent.summarize_news(company_input.value, days_slider.value)\n",
    "                    \n",
    "                    if \"error\" in result:\n",
    "                        print(f\"Error: {result['error']}\")\n",
    "                        print(\"Using sample data instead...\")\n",
    "                        analyze_sample_news()\n",
    "                    else:\n",
    "                        display(Markdown(\"### News Analysis\"))\n",
    "                        display(Markdown(result[\"analysis\"]))\n",
    "                        \n",
    "                        display(Markdown(\"\\n### Recent Articles\"))\n",
    "                        for i, article in enumerate(result[\"articles\"]):\n",
    "                            display(Markdown(f\"{i+1}. [{article['title']}]({article['url']}) - {article['source']} ({article['date']})\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\")\n",
    "                    print(\"Using sample data instead...\")\n",
    "                    analyze_sample_news()\n",
    "            else:\n",
    "                print(\"Please enter a company name.\")\n",
    "    \n",
    "    def on_sample_clicked(_):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            analyze_sample_news()\n",
    "    \n",
    "    button.on_click(on_api_analyze_clicked)\n",
    "    sample_button.on_click(on_sample_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>Financial News Analysis</h3>\"),\n",
    "        widgets.HBox([company_input, days_slider]),\n",
    "        api_key_input,\n",
    "        widgets.HBox([button, sample_button]),\n",
    "        output\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82d88614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193dcd8ef2c64ac1a44bd22275f47cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Financial News Analysis</h3>'), HBox(children=(Text(value='Infosys', descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display the news analysis widget\n",
    "news_widget = create_news_analysis_widget()\n",
    "display(news_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc7aba",
   "metadata": {},
   "source": [
    "### Integrating News Analysis with RAG System\n",
    "\n",
    "Now, let's integrate the news analysis with our RAG system to provide more comprehensive answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e072a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_news_context(query, company_name, vector_store, k=3, days=7):\n",
    "    \"\"\"Answer a question using both document context and recent news\"\"\"\n",
    "    print(f\"Searching document context for {query}...\")\n",
    "    # Get answer from RAG system\n",
    "    rag_answer, docs = answer_question(query, vector_store, k)\n",
    "    \n",
    "    # Get recent news analysis\n",
    "    print(f\"\\nFetching recent news for {company_name}...\")\n",
    "    try:\n",
    "        # Try to get real news if API key is set\n",
    "        if news_agent.api_key:\n",
    "            news_result = news_agent.summarize_news(company_name, days)\n",
    "            news_analysis = news_result.get(\"analysis\", \"No news analysis available.\")\n",
    "            news_sources = [a.get(\"title\", \"\") for a in news_result.get(\"articles\", [])][:3]\n",
    "        else:\n",
    "            # Use sample data if no API key\n",
    "            analysis_result = news_agent.analyze_sentiment(sample_news)\n",
    "            news_analysis = analysis_result.get(\"analysis\", \"No news analysis available.\")\n",
    "            news_sources = [a.get(\"title\", \"\") for a in sample_news]\n",
    "            print(\"Using sample news data (set API key for real-time news)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting news: {e}\")\n",
    "        news_analysis = \"Error retrieving news analysis.\"\n",
    "        news_sources = []\n",
    "    \n",
    "    # Combine both answers using Ollama\n",
    "    prompt = f\"\"\"\n",
    "    I need to answer a question about {company_name} using both historical document analysis and recent news.\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Analysis from historical documents:\n",
    "    {rag_answer}\n",
    "    \n",
    "    Recent news analysis:\n",
    "    {news_analysis}\n",
    "    \n",
    "    Please provide a comprehensive answer that incorporates both the historical context and recent developments.\n",
    "    Clearly distinguish between historical information and recent news when relevant.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"deepseek-r1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        combined_answer = response['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error combining answers: {e}\")\n",
    "        combined_answer = f\"Error generating combined answer. Historical answer: {rag_answer}\\n\\nRecent news: {news_analysis}\"\n",
    "    \n",
    "    return {\n",
    "        \"answer\": combined_answer,\n",
    "        \"historical_sources\": [doc.metadata.get(\"source\", \"Unknown\") for doc in docs],\n",
    "        \"news_sources\": news_sources\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58dfcd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive widget for comprehensive analysis\n",
    "def create_comprehensive_analysis_widget(vector_store):\n",
    "    \"\"\"Create a widget that combines RAG and news analysis\"\"\"\n",
    "    # Create widgets\n",
    "    question_input = widgets.Text(\n",
    "        value='What is the financial outlook for Infosys?',\n",
    "        description='Question:',\n",
    "        placeholder='Enter your question',\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    company_input = widgets.Text(\n",
    "        value='Infosys',\n",
    "        description='Company:',\n",
    "        placeholder='Company name',\n",
    "        layout=widgets.Layout(width='60%')\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Submit button\n",
    "    button = widgets.Button(\n",
    "        description='Get Analysis',\n",
    "        button_style='success',\n",
    "        tooltip='Click for comprehensive analysis',\n",
    "        icon='search'\n",
    "    )\n",
    "    \n",
    "    def on_button_clicked(_):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            if question_input.value.strip() and company_input.value.strip():\n",
    "                print(f\"Question: {question_input.value}\")\n",
    "                print(f\"Company: {company_input.value}\")\n",
    "                print(\"Generating comprehensive analysis...\\n\")\n",
    "                \n",
    "                result = answer_with_news_context(question_input.value, company_input.value, vector_store)\n",
    "                \n",
    "                display(Markdown(\"## Comprehensive Answer\"))\n",
    "                display(Markdown(result[\"answer\"]))\n",
    "                \n",
    "                display(Markdown(\"\\n### Sources Used\"))\n",
    "                display(Markdown(\"**Historical Documents:**\"))\n",
    "                for source in set(result[\"historical_sources\"]):\n",
    "                    display(Markdown(f\"- {source}\"))\n",
    "                    \n",
    "                display(Markdown(\"\\n**News Articles:**\"))\n",
    "                for source in result[\"news_sources\"]:\n",
    "                    display(Markdown(f\"- {source}\"))\n",
    "            else:\n",
    "                print(\"Please enter both a question and a company name.\")\n",
    "    \n",
    "    button.on_click(on_button_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>Comprehensive Financial Analysis</h3>\"),\n",
    "        widgets.HTML(\"<p>Combines historical document analysis with recent news</p>\"),\n",
    "        question_input,\n",
    "        company_input,\n",
    "        button,\n",
    "        output\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "414b2808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432245f7e0e54ffc8aacafd60ed12402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Comprehensive Financial Analysis</h3>'), HTML(value='<p>Combines historical doc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display the comprehensive analysis widget\n",
    "comprehensive_widget = create_comprehensive_analysis_widget(vector_store)\n",
    "display(comprehensive_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
